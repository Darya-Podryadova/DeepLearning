{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2d0b1009",
      "metadata": {
        "id": "2d0b1009"
      },
      "source": [
        "В этом документе рассматриваются основные конструкции PyTorch на примере задачи классификации набора данных Fashion MNIST. Основная цель лабораторной работы – знакомство с фреймворком PyTorch.\n",
        "\n",
        "Лабораторная работа основана на материалах, представленных на официальном сайте https://pytorch.org. Оригинальная версия материала доступна по ссылке https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html. Подробная документация PyTorch доступна по ссылке https://pytorch.org/docs/stable/index.html."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "332decdf",
      "metadata": {
        "id": "332decdf"
      },
      "source": [
        "### Используемые модули"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1d58c0",
      "metadata": {
        "id": "2d1d58c0"
      },
      "outputs": [],
      "source": [
        "# Основной модуль PyTorch\n",
        "import torch\n",
        "\n",
        "# Модуль, содержащий классы и функции, использующиеся для построения нейронных сетей\n",
        "from torch import nn\n",
        "\n",
        "# Класс, предоставляющий iterable вокруг набора данных (torch.utils.data.Dataset)\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Встроенные наборы данных для задач, связанных с изображениями, включающие Fashion MNIST\n",
        "from torchvision import datasets\n",
        "\n",
        "# Класс, преобразующий изображение PIL или массив numpy в torch.Tensor\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "#Вспомогательный модуль\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838ba577",
      "metadata": {
        "id": "838ba577"
      },
      "source": [
        "### Загрузка набора данных\n",
        "Набор данных Fashion MNIST может быть получен через datasets.FashionMNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f83fef8c",
      "metadata": {
        "id": "f83fef8c"
      },
      "outputs": [],
      "source": [
        "# Загрузка тренировочного набора данных\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Загрузка тестового набора данных\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d63f6c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "0d63f6c4",
        "outputId": "9c944dd5-80e3-473e-a243-3d8ea7ed5482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Набор данных: <class 'torchvision.datasets.mnist.FashionMNIST'>\n",
            "Длина: 60000\n",
            "Состоит из: <class 'tuple'>, включающих в себя \n",
            "<class 'torch.Tensor'> (изображение) \n",
            " и <class 'int'> (номер класса изображения)\n",
            "Размерность изображения: torch.Size([1, 28, 28])\n",
            "Пример изображения:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f359e2b25c0>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('Набор данных: ' + str(type(training_data)))\n",
        "print('Длина: ' + str(len(training_data)))\n",
        "print('Состоит из: ' + str(type(training_data[0])) +\n",
        "      ', включающих в себя \\n' + str(type(training_data[0][0])) + ' (изображение) ' +\n",
        "      '\\n и ' + str(type(training_data[0][1])) + ' (номер класса изображения)')\n",
        "print('Размерность изображения: ' + str(training_data[0][0].shape))\n",
        "print('Пример изображения:')\n",
        "plt.imshow(training_data[0][0].squeeze(), cmap = 'gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "786b394a",
      "metadata": {
        "id": "786b394a"
      },
      "source": [
        "### Использование DataLoader\n",
        "\n",
        "Класс DataLoader используется для итерации по набору данных. DataLoader поддерживает такие операции, как разделение на подвыборки, перемешивание и параллельную загрузку данных. В этой работе DataLoader используется для разделения набора данных на подвыборки размера 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d82d86a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d82d86a",
        "outputId": "e61440f1-3d30-4333-c6aa-35bc069b4c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность X [N, C, H, W]: torch.Size([16, 1, 28, 28])\n",
            "Размерность y: torch.Size([16]), тип: torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Размерность X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Размерность y: {y.shape}, тип: {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "919b0856",
      "metadata": {
        "id": "919b0856"
      },
      "source": [
        "### Создание модели\n",
        "\n",
        "PyTorch может использовать видеокарты с поддержкой CUDA, доступность которых проверяется через функцию torch.cuda.is_available().\n",
        "\n",
        "Модели в PyTorch представлены классами, которые наследуют базовый класс nn.Module.\n",
        "<br>Каждая можель должна иметь функцию forward, определяющую расчёты, производящиеся при использовании модели.\n",
        "<br>Используемые при расчётах слои создаются в конструкторе \\_\\_init__.\n",
        "<br>Для удобства расчётов несколько стоящих подряд слоёв могут быть объединены в одну переменную с помощью nn.Sequential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d8823b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d8823b2",
        "outputId": "7204a4d8-9990-46b3-bbc3-f2f91474a726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используется устройство: cpu\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Использование устройство CUDA, если оно доступно\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Используется устройство: {device}\")\n",
        "\n",
        "# Создание модели\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # Перед созданием слоёв выполняется вызов конструктора родительского класса\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e6d0da6",
      "metadata": {
        "id": "1e6d0da6"
      },
      "source": [
        "### Обучение модели\n",
        "\n",
        "При обучении модели используется функция потерь nn.CrossEntropyLoss и метод оптимизации torch.optim.SGD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63377cb1",
      "metadata": {
        "id": "63377cb1"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7535cac2",
      "metadata": {
        "id": "7535cac2"
      },
      "source": [
        "При обучении модель определяет классы изображений в тренировочном наборе данных (разделённом на подвыборки), после чего выполняет обратное распространение ошибки для корректировки параметров модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c11bd3a",
      "metadata": {
        "id": "7c11bd3a"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train() # Перевод модели в режим обучения\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device) # Данные и модель должны находиться на одном устройстве\n",
        "\n",
        "        # Расчёт потерь\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Обратное распространение ошибки\n",
        "        optimizer.zero_grad() # Обнуление ранее рассчитанных градиентов\n",
        "        loss.backward() # Расчёт новых градиентов\n",
        "        optimizer.step() # Изменение весов (шаг обучения)\n",
        "\n",
        "        if batch % 100 == 0: # Вывод информации каждые 100 итераций\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a533445",
      "metadata": {
        "id": "4a533445"
      },
      "source": [
        "Также может быть определена функция тестирования для проверки качества обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cce16641",
      "metadata": {
        "id": "cce16641"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval() # Перевод модели в режим тестирования\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad(): # Отключение расчёта градиентов для ускорения работы\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e7e76d",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1e7e76d",
        "outputId": "c0a04d5a-26e7-4e31-a953-329e9aa1b880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.291838  [    0/60000]\n",
            "loss: 2.277162  [ 1600/60000]\n",
            "loss: 2.283946  [ 3200/60000]\n",
            "loss: 2.261334  [ 4800/60000]\n",
            "loss: 2.233647  [ 6400/60000]\n",
            "loss: 2.213686  [ 8000/60000]\n",
            "loss: 2.210100  [ 9600/60000]\n",
            "loss: 2.153640  [11200/60000]\n",
            "loss: 2.196994  [12800/60000]\n",
            "loss: 2.135398  [14400/60000]\n",
            "loss: 2.136382  [16000/60000]\n",
            "loss: 2.113517  [17600/60000]\n",
            "loss: 2.097002  [19200/60000]\n",
            "loss: 2.076400  [20800/60000]\n",
            "loss: 2.069687  [22400/60000]\n",
            "loss: 2.017707  [24000/60000]\n",
            "loss: 1.982826  [25600/60000]\n",
            "loss: 2.043973  [27200/60000]\n",
            "loss: 1.937813  [28800/60000]\n",
            "loss: 1.906235  [30400/60000]\n",
            "loss: 1.805796  [32000/60000]\n",
            "loss: 1.765758  [33600/60000]\n",
            "loss: 1.646275  [35200/60000]\n",
            "loss: 1.794698  [36800/60000]\n",
            "loss: 1.832621  [38400/60000]\n",
            "loss: 1.633617  [40000/60000]\n",
            "loss: 1.561120  [41600/60000]\n",
            "loss: 1.666707  [43200/60000]\n",
            "loss: 1.377500  [44800/60000]\n",
            "loss: 1.509094  [46400/60000]\n",
            "loss: 1.540887  [48000/60000]\n",
            "loss: 1.341809  [49600/60000]\n",
            "loss: 1.410061  [51200/60000]\n",
            "loss: 1.372765  [52800/60000]\n",
            "loss: 1.279336  [54400/60000]\n",
            "loss: 1.367906  [56000/60000]\n",
            "loss: 1.277990  [57600/60000]\n",
            "loss: 1.056350  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.1%, Avg loss: 1.261133 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.280578  [    0/60000]\n",
            "loss: 1.145162  [ 1600/60000]\n",
            "loss: 1.191051  [ 3200/60000]\n",
            "loss: 1.232612  [ 4800/60000]\n",
            "loss: 1.131630  [ 6400/60000]\n",
            "loss: 1.266665  [ 8000/60000]\n",
            "loss: 1.203277  [ 9600/60000]\n",
            "loss: 1.048340  [11200/60000]\n",
            "loss: 1.104078  [12800/60000]\n",
            "loss: 1.110368  [14400/60000]\n",
            "loss: 1.141605  [16000/60000]\n",
            "loss: 0.999561  [17600/60000]\n",
            "loss: 0.886440  [19200/60000]\n",
            "loss: 1.441176  [20800/60000]\n",
            "loss: 1.117504  [22400/60000]\n",
            "loss: 1.086782  [24000/60000]\n",
            "loss: 0.848525  [25600/60000]\n",
            "loss: 1.172747  [27200/60000]\n",
            "loss: 1.168481  [28800/60000]\n",
            "loss: 1.016420  [30400/60000]\n",
            "loss: 0.940774  [32000/60000]\n",
            "loss: 0.660040  [33600/60000]\n",
            "loss: 0.761289  [35200/60000]\n",
            "loss: 1.002675  [36800/60000]\n",
            "loss: 1.249769  [38400/60000]\n",
            "loss: 0.835461  [40000/60000]\n",
            "loss: 0.891298  [41600/60000]\n",
            "loss: 0.902596  [43200/60000]\n",
            "loss: 0.651226  [44800/60000]\n",
            "loss: 0.875592  [46400/60000]\n",
            "loss: 0.856521  [48000/60000]\n",
            "loss: 0.734494  [49600/60000]\n",
            "loss: 0.789313  [51200/60000]\n",
            "loss: 0.832106  [52800/60000]\n",
            "loss: 0.815965  [54400/60000]\n",
            "loss: 1.087882  [56000/60000]\n",
            "loss: 0.862595  [57600/60000]\n",
            "loss: 0.622785  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.7%, Avg loss: 0.863939 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.857098  [    0/60000]\n",
            "loss: 0.728660  [ 1600/60000]\n",
            "loss: 0.767250  [ 3200/60000]\n",
            "loss: 0.844338  [ 4800/60000]\n",
            "loss: 0.739492  [ 6400/60000]\n",
            "loss: 0.908205  [ 8000/60000]\n",
            "loss: 0.894176  [ 9600/60000]\n",
            "loss: 0.654271  [11200/60000]\n",
            "loss: 0.819643  [12800/60000]\n",
            "loss: 0.719178  [14400/60000]\n",
            "loss: 0.877030  [16000/60000]\n",
            "loss: 0.684857  [17600/60000]\n",
            "loss: 0.616358  [19200/60000]\n",
            "loss: 1.337512  [20800/60000]\n",
            "loss: 0.843425  [22400/60000]\n",
            "loss: 0.870370  [24000/60000]\n",
            "loss: 0.583240  [25600/60000]\n",
            "loss: 0.994486  [27200/60000]\n",
            "loss: 1.081115  [28800/60000]\n",
            "loss: 0.738379  [30400/60000]\n",
            "loss: 0.773155  [32000/60000]\n",
            "loss: 0.427009  [33600/60000]\n",
            "loss: 0.532200  [35200/60000]\n",
            "loss: 0.772596  [36800/60000]\n",
            "loss: 1.139754  [38400/60000]\n",
            "loss: 0.715452  [40000/60000]\n",
            "loss: 0.762478  [41600/60000]\n",
            "loss: 0.690815  [43200/60000]\n",
            "loss: 0.510056  [44800/60000]\n",
            "loss: 0.702104  [46400/60000]\n",
            "loss: 0.669910  [48000/60000]\n",
            "loss: 0.575383  [49600/60000]\n",
            "loss: 0.603989  [51200/60000]\n",
            "loss: 0.674912  [52800/60000]\n",
            "loss: 0.713286  [54400/60000]\n",
            "loss: 0.992565  [56000/60000]\n",
            "loss: 0.785938  [57600/60000]\n",
            "loss: 0.535044  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 72.2%, Avg loss: 0.746288 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.747686  [    0/60000]\n",
            "loss: 0.629310  [ 1600/60000]\n",
            "loss: 0.667403  [ 3200/60000]\n",
            "loss: 0.695349  [ 4800/60000]\n",
            "loss: 0.609737  [ 6400/60000]\n",
            "loss: 0.764616  [ 8000/60000]\n",
            "loss: 0.774971  [ 9600/60000]\n",
            "loss: 0.511344  [11200/60000]\n",
            "loss: 0.714125  [12800/60000]\n",
            "loss: 0.536515  [14400/60000]\n",
            "loss: 0.812039  [16000/60000]\n",
            "loss: 0.559460  [17600/60000]\n",
            "loss: 0.514004  [19200/60000]\n",
            "loss: 1.241561  [20800/60000]\n",
            "loss: 0.715625  [22400/60000]\n",
            "loss: 0.788318  [24000/60000]\n",
            "loss: 0.510283  [25600/60000]\n",
            "loss: 0.932962  [27200/60000]\n",
            "loss: 1.003704  [28800/60000]\n",
            "loss: 0.612893  [30400/60000]\n",
            "loss: 0.744201  [32000/60000]\n",
            "loss: 0.342740  [33600/60000]\n",
            "loss: 0.440570  [35200/60000]\n",
            "loss: 0.661049  [36800/60000]\n",
            "loss: 1.018900  [38400/60000]\n",
            "loss: 0.709350  [40000/60000]\n",
            "loss: 0.709278  [41600/60000]\n",
            "loss: 0.597156  [43200/60000]\n",
            "loss: 0.464177  [44800/60000]\n",
            "loss: 0.628339  [46400/60000]\n",
            "loss: 0.566075  [48000/60000]\n",
            "loss: 0.515697  [49600/60000]\n",
            "loss: 0.495870  [51200/60000]\n",
            "loss: 0.580544  [52800/60000]\n",
            "loss: 0.672752  [54400/60000]\n",
            "loss: 0.889642  [56000/60000]\n",
            "loss: 0.749703  [57600/60000]\n",
            "loss: 0.482091  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 76.0%, Avg loss: 0.678706 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.665532  [    0/60000]\n",
            "loss: 0.583381  [ 1600/60000]\n",
            "loss: 0.622845  [ 3200/60000]\n",
            "loss: 0.603983  [ 4800/60000]\n",
            "loss: 0.525502  [ 6400/60000]\n",
            "loss: 0.679776  [ 8000/60000]\n",
            "loss: 0.705590  [ 9600/60000]\n",
            "loss: 0.432862  [11200/60000]\n",
            "loss: 0.628954  [12800/60000]\n",
            "loss: 0.428192  [14400/60000]\n",
            "loss: 0.783317  [16000/60000]\n",
            "loss: 0.471619  [17600/60000]\n",
            "loss: 0.447717  [19200/60000]\n",
            "loss: 1.178921  [20800/60000]\n",
            "loss: 0.622635  [22400/60000]\n",
            "loss: 0.736590  [24000/60000]\n",
            "loss: 0.482152  [25600/60000]\n",
            "loss: 0.874226  [27200/60000]\n",
            "loss: 0.921571  [28800/60000]\n",
            "loss: 0.534527  [30400/60000]\n",
            "loss: 0.730415  [32000/60000]\n",
            "loss: 0.292061  [33600/60000]\n",
            "loss: 0.380248  [35200/60000]\n",
            "loss: 0.579969  [36800/60000]\n",
            "loss: 0.901118  [38400/60000]\n",
            "loss: 0.724252  [40000/60000]\n",
            "loss: 0.674388  [41600/60000]\n",
            "loss: 0.535976  [43200/60000]\n",
            "loss: 0.440088  [44800/60000]\n",
            "loss: 0.578043  [46400/60000]\n",
            "loss: 0.496202  [48000/60000]\n",
            "loss: 0.484860  [49600/60000]\n",
            "loss: 0.414172  [51200/60000]\n",
            "loss: 0.504953  [52800/60000]\n",
            "loss: 0.649880  [54400/60000]\n",
            "loss: 0.789039  [56000/60000]\n",
            "loss: 0.716527  [57600/60000]\n",
            "loss: 0.433443  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 0.628949 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.603882  [    0/60000]\n",
            "loss: 0.544045  [ 1600/60000]\n",
            "loss: 0.597141  [ 3200/60000]\n",
            "loss: 0.541534  [ 4800/60000]\n",
            "loss: 0.456538  [ 6400/60000]\n",
            "loss: 0.622354  [ 8000/60000]\n",
            "loss: 0.655791  [ 9600/60000]\n",
            "loss: 0.380335  [11200/60000]\n",
            "loss: 0.558038  [12800/60000]\n",
            "loss: 0.352265  [14400/60000]\n",
            "loss: 0.766743  [16000/60000]\n",
            "loss: 0.403105  [17600/60000]\n",
            "loss: 0.402262  [19200/60000]\n",
            "loss: 1.140727  [20800/60000]\n",
            "loss: 0.547871  [22400/60000]\n",
            "loss: 0.699523  [24000/60000]\n",
            "loss: 0.465896  [25600/60000]\n",
            "loss: 0.816036  [27200/60000]\n",
            "loss: 0.842417  [28800/60000]\n",
            "loss: 0.478626  [30400/60000]\n",
            "loss: 0.709427  [32000/60000]\n",
            "loss: 0.255821  [33600/60000]\n",
            "loss: 0.332815  [35200/60000]\n",
            "loss: 0.510406  [36800/60000]\n",
            "loss: 0.797120  [38400/60000]\n",
            "loss: 0.740277  [40000/60000]\n",
            "loss: 0.652136  [41600/60000]\n",
            "loss: 0.489139  [43200/60000]\n",
            "loss: 0.431080  [44800/60000]\n",
            "loss: 0.541079  [46400/60000]\n",
            "loss: 0.451015  [48000/60000]\n",
            "loss: 0.464269  [49600/60000]\n",
            "loss: 0.355350  [51200/60000]\n",
            "loss: 0.444251  [52800/60000]\n",
            "loss: 0.635567  [54400/60000]\n",
            "loss: 0.701859  [56000/60000]\n",
            "loss: 0.685921  [57600/60000]\n",
            "loss: 0.394877  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.4%, Avg loss: 0.592126 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.561282  [    0/60000]\n",
            "loss: 0.503655  [ 1600/60000]\n",
            "loss: 0.584482  [ 3200/60000]\n",
            "loss: 0.499130  [ 4800/60000]\n",
            "loss: 0.400126  [ 6400/60000]\n",
            "loss: 0.583636  [ 8000/60000]\n",
            "loss: 0.617818  [ 9600/60000]\n",
            "loss: 0.344168  [11200/60000]\n",
            "loss: 0.502659  [12800/60000]\n",
            "loss: 0.298364  [14400/60000]\n",
            "loss: 0.755740  [16000/60000]\n",
            "loss: 0.350021  [17600/60000]\n",
            "loss: 0.372753  [19200/60000]\n",
            "loss: 1.115849  [20800/60000]\n",
            "loss: 0.493990  [22400/60000]\n",
            "loss: 0.673680  [24000/60000]\n",
            "loss: 0.450552  [25600/60000]\n",
            "loss: 0.767246  [27200/60000]\n",
            "loss: 0.777276  [28800/60000]\n",
            "loss: 0.436448  [30400/60000]\n",
            "loss: 0.680786  [32000/60000]\n",
            "loss: 0.231399  [33600/60000]\n",
            "loss: 0.297606  [35200/60000]\n",
            "loss: 0.453694  [36800/60000]\n",
            "loss: 0.712625  [38400/60000]\n",
            "loss: 0.751782  [40000/60000]\n",
            "loss: 0.640115  [41600/60000]\n",
            "loss: 0.453999  [43200/60000]\n",
            "loss: 0.432768  [44800/60000]\n",
            "loss: 0.516327  [46400/60000]\n",
            "loss: 0.422528  [48000/60000]\n",
            "loss: 0.447202  [49600/60000]\n",
            "loss: 0.315660  [51200/60000]\n",
            "loss: 0.399506  [52800/60000]\n",
            "loss: 0.625121  [54400/60000]\n",
            "loss: 0.631248  [56000/60000]\n",
            "loss: 0.659186  [57600/60000]\n",
            "loss: 0.367984  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.3%, Avg loss: 0.565004 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.529434  [    0/60000]\n",
            "loss: 0.464993  [ 1600/60000]\n",
            "loss: 0.579199  [ 3200/60000]\n",
            "loss: 0.469867  [ 4800/60000]\n",
            "loss: 0.357493  [ 6400/60000]\n",
            "loss: 0.555980  [ 8000/60000]\n",
            "loss: 0.588951  [ 9600/60000]\n",
            "loss: 0.320653  [11200/60000]\n",
            "loss: 0.459757  [12800/60000]\n",
            "loss: 0.258847  [14400/60000]\n",
            "loss: 0.747544  [16000/60000]\n",
            "loss: 0.308781  [17600/60000]\n",
            "loss: 0.352020  [19200/60000]\n",
            "loss: 1.096398  [20800/60000]\n",
            "loss: 0.456269  [22400/60000]\n",
            "loss: 0.656500  [24000/60000]\n",
            "loss: 0.433904  [25600/60000]\n",
            "loss: 0.727973  [27200/60000]\n",
            "loss: 0.726736  [28800/60000]\n",
            "loss: 0.404156  [30400/60000]\n",
            "loss: 0.649691  [32000/60000]\n",
            "loss: 0.216145  [33600/60000]\n",
            "loss: 0.272530  [35200/60000]\n",
            "loss: 0.411032  [36800/60000]\n",
            "loss: 0.646529  [38400/60000]\n",
            "loss: 0.760411  [40000/60000]\n",
            "loss: 0.634275  [41600/60000]\n",
            "loss: 0.428760  [43200/60000]\n",
            "loss: 0.439621  [44800/60000]\n",
            "loss: 0.500578  [46400/60000]\n",
            "loss: 0.403843  [48000/60000]\n",
            "loss: 0.431448  [49600/60000]\n",
            "loss: 0.289495  [51200/60000]\n",
            "loss: 0.369283  [52800/60000]\n",
            "loss: 0.616571  [54400/60000]\n",
            "loss: 0.575501  [56000/60000]\n",
            "loss: 0.636149  [57600/60000]\n",
            "loss: 0.350406  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 0.544633 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.502091  [    0/60000]\n",
            "loss: 0.431952  [ 1600/60000]\n",
            "loss: 0.575585  [ 3200/60000]\n",
            "loss: 0.448183  [ 4800/60000]\n",
            "loss: 0.327503  [ 6400/60000]\n",
            "loss: 0.536340  [ 8000/60000]\n",
            "loss: 0.567114  [ 9600/60000]\n",
            "loss: 0.305090  [11200/60000]\n",
            "loss: 0.426521  [12800/60000]\n",
            "loss: 0.228397  [14400/60000]\n",
            "loss: 0.740618  [16000/60000]\n",
            "loss: 0.276820  [17600/60000]\n",
            "loss: 0.335459  [19200/60000]\n",
            "loss: 1.076485  [20800/60000]\n",
            "loss: 0.428954  [22400/60000]\n",
            "loss: 0.644878  [24000/60000]\n",
            "loss: 0.417844  [25600/60000]\n",
            "loss: 0.693857  [27200/60000]\n",
            "loss: 0.690137  [28800/60000]\n",
            "loss: 0.377866  [30400/60000]\n",
            "loss: 0.620902  [32000/60000]\n",
            "loss: 0.207221  [33600/60000]\n",
            "loss: 0.254741  [35200/60000]\n",
            "loss: 0.380842  [36800/60000]\n",
            "loss: 0.594270  [38400/60000]\n",
            "loss: 0.766146  [40000/60000]\n",
            "loss: 0.631249  [41600/60000]\n",
            "loss: 0.410405  [43200/60000]\n",
            "loss: 0.446417  [44800/60000]\n",
            "loss: 0.490176  [46400/60000]\n",
            "loss: 0.390165  [48000/60000]\n",
            "loss: 0.417107  [49600/60000]\n",
            "loss: 0.272114  [51200/60000]\n",
            "loss: 0.350643  [52800/60000]\n",
            "loss: 0.608588  [54400/60000]\n",
            "loss: 0.529586  [56000/60000]\n",
            "loss: 0.615553  [57600/60000]\n",
            "loss: 0.339912  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.528880 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.476932  [    0/60000]\n",
            "loss: 0.406242  [ 1600/60000]\n",
            "loss: 0.570397  [ 3200/60000]\n",
            "loss: 0.430811  [ 4800/60000]\n",
            "loss: 0.307431  [ 6400/60000]\n",
            "loss: 0.521607  [ 8000/60000]\n",
            "loss: 0.551329  [ 9600/60000]\n",
            "loss: 0.294854  [11200/60000]\n",
            "loss: 0.400577  [12800/60000]\n",
            "loss: 0.204370  [14400/60000]\n",
            "loss: 0.734166  [16000/60000]\n",
            "loss: 0.251396  [17600/60000]\n",
            "loss: 0.320302  [19200/60000]\n",
            "loss: 1.055923  [20800/60000]\n",
            "loss: 0.407822  [22400/60000]\n",
            "loss: 0.636290  [24000/60000]\n",
            "loss: 0.402727  [25600/60000]\n",
            "loss: 0.664673  [27200/60000]\n",
            "loss: 0.663583  [28800/60000]\n",
            "loss: 0.356587  [30400/60000]\n",
            "loss: 0.596563  [32000/60000]\n",
            "loss: 0.202290  [33600/60000]\n",
            "loss: 0.241659  [35200/60000]\n",
            "loss: 0.360045  [36800/60000]\n",
            "loss: 0.551320  [38400/60000]\n",
            "loss: 0.770978  [40000/60000]\n",
            "loss: 0.629211  [41600/60000]\n",
            "loss: 0.397774  [43200/60000]\n",
            "loss: 0.452511  [44800/60000]\n",
            "loss: 0.482304  [46400/60000]\n",
            "loss: 0.379249  [48000/60000]\n",
            "loss: 0.403755  [49600/60000]\n",
            "loss: 0.259717  [51200/60000]\n",
            "loss: 0.339810  [52800/60000]\n",
            "loss: 0.601499  [54400/60000]\n",
            "loss: 0.491440  [56000/60000]\n",
            "loss: 0.598451  [57600/60000]\n",
            "loss: 0.333663  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 0.516328 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.453650  [    0/60000]\n",
            "loss: 0.386753  [ 1600/60000]\n",
            "loss: 0.561255  [ 3200/60000]\n",
            "loss: 0.416320  [ 4800/60000]\n",
            "loss: 0.293700  [ 6400/60000]\n",
            "loss: 0.511288  [ 8000/60000]\n",
            "loss: 0.539852  [ 9600/60000]\n",
            "loss: 0.288078  [11200/60000]\n",
            "loss: 0.380010  [12800/60000]\n",
            "loss: 0.184994  [14400/60000]\n",
            "loss: 0.726814  [16000/60000]\n",
            "loss: 0.230953  [17600/60000]\n",
            "loss: 0.305756  [19200/60000]\n",
            "loss: 1.033867  [20800/60000]\n",
            "loss: 0.390943  [22400/60000]\n",
            "loss: 0.629285  [24000/60000]\n",
            "loss: 0.389994  [25600/60000]\n",
            "loss: 0.640508  [27200/60000]\n",
            "loss: 0.643848  [28800/60000]\n",
            "loss: 0.339530  [30400/60000]\n",
            "loss: 0.577854  [32000/60000]\n",
            "loss: 0.199301  [33600/60000]\n",
            "loss: 0.231458  [35200/60000]\n",
            "loss: 0.346251  [36800/60000]\n",
            "loss: 0.515723  [38400/60000]\n",
            "loss: 0.775711  [40000/60000]\n",
            "loss: 0.626321  [41600/60000]\n",
            "loss: 0.389286  [43200/60000]\n",
            "loss: 0.455946  [44800/60000]\n",
            "loss: 0.475937  [46400/60000]\n",
            "loss: 0.369653  [48000/60000]\n",
            "loss: 0.391329  [49600/60000]\n",
            "loss: 0.250548  [51200/60000]\n",
            "loss: 0.333528  [52800/60000]\n",
            "loss: 0.594639  [54400/60000]\n",
            "loss: 0.459087  [56000/60000]\n",
            "loss: 0.584035  [57600/60000]\n",
            "loss: 0.329744  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 0.505988 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.432315  [    0/60000]\n",
            "loss: 0.372693  [ 1600/60000]\n",
            "loss: 0.548731  [ 3200/60000]\n",
            "loss: 0.403333  [ 4800/60000]\n",
            "loss: 0.284153  [ 6400/60000]\n",
            "loss: 0.503920  [ 8000/60000]\n",
            "loss: 0.531907  [ 9600/60000]\n",
            "loss: 0.282834  [11200/60000]\n",
            "loss: 0.363386  [12800/60000]\n",
            "loss: 0.169300  [14400/60000]\n",
            "loss: 0.720089  [16000/60000]\n",
            "loss: 0.214855  [17600/60000]\n",
            "loss: 0.291665  [19200/60000]\n",
            "loss: 1.011463  [20800/60000]\n",
            "loss: 0.377159  [22400/60000]\n",
            "loss: 0.624104  [24000/60000]\n",
            "loss: 0.378991  [25600/60000]\n",
            "loss: 0.620833  [27200/60000]\n",
            "loss: 0.629026  [28800/60000]\n",
            "loss: 0.326574  [30400/60000]\n",
            "loss: 0.564955  [32000/60000]\n",
            "loss: 0.196989  [33600/60000]\n",
            "loss: 0.223067  [35200/60000]\n",
            "loss: 0.337758  [36800/60000]\n",
            "loss: 0.485361  [38400/60000]\n",
            "loss: 0.780344  [40000/60000]\n",
            "loss: 0.622778  [41600/60000]\n",
            "loss: 0.383092  [43200/60000]\n",
            "loss: 0.456804  [44800/60000]\n",
            "loss: 0.471112  [46400/60000]\n",
            "loss: 0.361538  [48000/60000]\n",
            "loss: 0.380895  [49600/60000]\n",
            "loss: 0.242915  [51200/60000]\n",
            "loss: 0.331098  [52800/60000]\n",
            "loss: 0.587355  [54400/60000]\n",
            "loss: 0.431606  [56000/60000]\n",
            "loss: 0.572385  [57600/60000]\n",
            "loss: 0.326357  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 0.497341 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.414103  [    0/60000]\n",
            "loss: 0.361839  [ 1600/60000]\n",
            "loss: 0.535795  [ 3200/60000]\n",
            "loss: 0.392432  [ 4800/60000]\n",
            "loss: 0.277162  [ 6400/60000]\n",
            "loss: 0.498262  [ 8000/60000]\n",
            "loss: 0.526975  [ 9600/60000]\n",
            "loss: 0.277852  [11200/60000]\n",
            "loss: 0.349790  [12800/60000]\n",
            "loss: 0.156671  [14400/60000]\n",
            "loss: 0.713997  [16000/60000]\n",
            "loss: 0.201832  [17600/60000]\n",
            "loss: 0.278422  [19200/60000]\n",
            "loss: 0.987510  [20800/60000]\n",
            "loss: 0.364933  [22400/60000]\n",
            "loss: 0.620197  [24000/60000]\n",
            "loss: 0.369903  [25600/60000]\n",
            "loss: 0.604731  [27200/60000]\n",
            "loss: 0.616915  [28800/60000]\n",
            "loss: 0.315944  [30400/60000]\n",
            "loss: 0.556997  [32000/60000]\n",
            "loss: 0.195319  [33600/60000]\n",
            "loss: 0.216219  [35200/60000]\n",
            "loss: 0.333234  [36800/60000]\n",
            "loss: 0.459637  [38400/60000]\n",
            "loss: 0.784925  [40000/60000]\n",
            "loss: 0.619274  [41600/60000]\n",
            "loss: 0.378972  [43200/60000]\n",
            "loss: 0.456483  [44800/60000]\n",
            "loss: 0.467109  [46400/60000]\n",
            "loss: 0.353887  [48000/60000]\n",
            "loss: 0.371062  [49600/60000]\n",
            "loss: 0.236357  [51200/60000]\n",
            "loss: 0.330579  [52800/60000]\n",
            "loss: 0.580291  [54400/60000]\n",
            "loss: 0.407662  [56000/60000]\n",
            "loss: 0.564129  [57600/60000]\n",
            "loss: 0.322970  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 0.489930 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.398523  [    0/60000]\n",
            "loss: 0.353230  [ 1600/60000]\n",
            "loss: 0.521492  [ 3200/60000]\n",
            "loss: 0.383213  [ 4800/60000]\n",
            "loss: 0.271674  [ 6400/60000]\n",
            "loss: 0.493673  [ 8000/60000]\n",
            "loss: 0.523915  [ 9600/60000]\n",
            "loss: 0.272933  [11200/60000]\n",
            "loss: 0.338411  [12800/60000]\n",
            "loss: 0.146480  [14400/60000]\n",
            "loss: 0.709092  [16000/60000]\n",
            "loss: 0.191615  [17600/60000]\n",
            "loss: 0.266220  [19200/60000]\n",
            "loss: 0.965237  [20800/60000]\n",
            "loss: 0.354420  [22400/60000]\n",
            "loss: 0.616257  [24000/60000]\n",
            "loss: 0.362313  [25600/60000]\n",
            "loss: 0.591495  [27200/60000]\n",
            "loss: 0.606291  [28800/60000]\n",
            "loss: 0.307279  [30400/60000]\n",
            "loss: 0.553226  [32000/60000]\n",
            "loss: 0.193566  [33600/60000]\n",
            "loss: 0.210471  [35200/60000]\n",
            "loss: 0.331515  [36800/60000]\n",
            "loss: 0.436615  [38400/60000]\n",
            "loss: 0.788018  [40000/60000]\n",
            "loss: 0.615447  [41600/60000]\n",
            "loss: 0.376326  [43200/60000]\n",
            "loss: 0.455156  [44800/60000]\n",
            "loss: 0.463976  [46400/60000]\n",
            "loss: 0.346660  [48000/60000]\n",
            "loss: 0.361723  [49600/60000]\n",
            "loss: 0.229974  [51200/60000]\n",
            "loss: 0.331765  [52800/60000]\n",
            "loss: 0.574021  [54400/60000]\n",
            "loss: 0.386618  [56000/60000]\n",
            "loss: 0.557516  [57600/60000]\n",
            "loss: 0.319624  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.483445 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.384595  [    0/60000]\n",
            "loss: 0.346556  [ 1600/60000]\n",
            "loss: 0.506895  [ 3200/60000]\n",
            "loss: 0.375620  [ 4800/60000]\n",
            "loss: 0.266808  [ 6400/60000]\n",
            "loss: 0.490473  [ 8000/60000]\n",
            "loss: 0.521896  [ 9600/60000]\n",
            "loss: 0.267374  [11200/60000]\n",
            "loss: 0.328897  [12800/60000]\n",
            "loss: 0.138256  [14400/60000]\n",
            "loss: 0.704231  [16000/60000]\n",
            "loss: 0.183282  [17600/60000]\n",
            "loss: 0.255184  [19200/60000]\n",
            "loss: 0.941796  [20800/60000]\n",
            "loss: 0.346022  [22400/60000]\n",
            "loss: 0.612095  [24000/60000]\n",
            "loss: 0.356607  [25600/60000]\n",
            "loss: 0.581664  [27200/60000]\n",
            "loss: 0.596349  [28800/60000]\n",
            "loss: 0.300572  [30400/60000]\n",
            "loss: 0.553169  [32000/60000]\n",
            "loss: 0.191671  [33600/60000]\n",
            "loss: 0.205685  [35200/60000]\n",
            "loss: 0.331465  [36800/60000]\n",
            "loss: 0.415675  [38400/60000]\n",
            "loss: 0.790301  [40000/60000]\n",
            "loss: 0.611411  [41600/60000]\n",
            "loss: 0.375519  [43200/60000]\n",
            "loss: 0.455018  [44800/60000]\n",
            "loss: 0.461593  [46400/60000]\n",
            "loss: 0.340283  [48000/60000]\n",
            "loss: 0.352291  [49600/60000]\n",
            "loss: 0.223765  [51200/60000]\n",
            "loss: 0.333092  [52800/60000]\n",
            "loss: 0.568214  [54400/60000]\n",
            "loss: 0.367780  [56000/60000]\n",
            "loss: 0.552909  [57600/60000]\n",
            "loss: 0.315035  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.1%, Avg loss: 0.477643 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.373305  [    0/60000]\n",
            "loss: 0.341228  [ 1600/60000]\n",
            "loss: 0.492306  [ 3200/60000]\n",
            "loss: 0.369226  [ 4800/60000]\n",
            "loss: 0.262558  [ 6400/60000]\n",
            "loss: 0.488320  [ 8000/60000]\n",
            "loss: 0.521156  [ 9600/60000]\n",
            "loss: 0.261846  [11200/60000]\n",
            "loss: 0.321230  [12800/60000]\n",
            "loss: 0.131265  [14400/60000]\n",
            "loss: 0.700340  [16000/60000]\n",
            "loss: 0.176488  [17600/60000]\n",
            "loss: 0.245356  [19200/60000]\n",
            "loss: 0.918592  [20800/60000]\n",
            "loss: 0.339778  [22400/60000]\n",
            "loss: 0.607261  [24000/60000]\n",
            "loss: 0.351207  [25600/60000]\n",
            "loss: 0.574106  [27200/60000]\n",
            "loss: 0.586928  [28800/60000]\n",
            "loss: 0.295945  [30400/60000]\n",
            "loss: 0.555276  [32000/60000]\n",
            "loss: 0.189303  [33600/60000]\n",
            "loss: 0.201787  [35200/60000]\n",
            "loss: 0.332872  [36800/60000]\n",
            "loss: 0.396439  [38400/60000]\n",
            "loss: 0.790924  [40000/60000]\n",
            "loss: 0.607174  [41600/60000]\n",
            "loss: 0.375842  [43200/60000]\n",
            "loss: 0.454859  [44800/60000]\n",
            "loss: 0.459916  [46400/60000]\n",
            "loss: 0.334404  [48000/60000]\n",
            "loss: 0.343337  [49600/60000]\n",
            "loss: 0.218520  [51200/60000]\n",
            "loss: 0.334767  [52800/60000]\n",
            "loss: 0.562427  [54400/60000]\n",
            "loss: 0.351594  [56000/60000]\n",
            "loss: 0.549267  [57600/60000]\n",
            "loss: 0.310344  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.472306 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.363589  [    0/60000]\n",
            "loss: 0.337386  [ 1600/60000]\n",
            "loss: 0.478168  [ 3200/60000]\n",
            "loss: 0.363468  [ 4800/60000]\n",
            "loss: 0.258516  [ 6400/60000]\n",
            "loss: 0.485651  [ 8000/60000]\n",
            "loss: 0.521073  [ 9600/60000]\n",
            "loss: 0.256431  [11200/60000]\n",
            "loss: 0.314886  [12800/60000]\n",
            "loss: 0.125986  [14400/60000]\n",
            "loss: 0.696825  [16000/60000]\n",
            "loss: 0.170980  [17600/60000]\n",
            "loss: 0.236442  [19200/60000]\n",
            "loss: 0.899774  [20800/60000]\n",
            "loss: 0.333490  [22400/60000]\n",
            "loss: 0.601628  [24000/60000]\n",
            "loss: 0.347091  [25600/60000]\n",
            "loss: 0.566577  [27200/60000]\n",
            "loss: 0.578222  [28800/60000]\n",
            "loss: 0.292013  [30400/60000]\n",
            "loss: 0.557173  [32000/60000]\n",
            "loss: 0.187266  [33600/60000]\n",
            "loss: 0.198514  [35200/60000]\n",
            "loss: 0.334850  [36800/60000]\n",
            "loss: 0.378994  [38400/60000]\n",
            "loss: 0.791272  [40000/60000]\n",
            "loss: 0.602382  [41600/60000]\n",
            "loss: 0.377370  [43200/60000]\n",
            "loss: 0.453931  [44800/60000]\n",
            "loss: 0.458663  [46400/60000]\n",
            "loss: 0.328916  [48000/60000]\n",
            "loss: 0.334835  [49600/60000]\n",
            "loss: 0.214076  [51200/60000]\n",
            "loss: 0.336282  [52800/60000]\n",
            "loss: 0.556839  [54400/60000]\n",
            "loss: 0.336626  [56000/60000]\n",
            "loss: 0.547289  [57600/60000]\n",
            "loss: 0.307965  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.467489 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.355645  [    0/60000]\n",
            "loss: 0.334670  [ 1600/60000]\n",
            "loss: 0.464402  [ 3200/60000]\n",
            "loss: 0.357621  [ 4800/60000]\n",
            "loss: 0.254777  [ 6400/60000]\n",
            "loss: 0.483624  [ 8000/60000]\n",
            "loss: 0.521003  [ 9600/60000]\n",
            "loss: 0.251024  [11200/60000]\n",
            "loss: 0.308537  [12800/60000]\n",
            "loss: 0.121573  [14400/60000]\n",
            "loss: 0.693669  [16000/60000]\n",
            "loss: 0.166699  [17600/60000]\n",
            "loss: 0.228390  [19200/60000]\n",
            "loss: 0.882399  [20800/60000]\n",
            "loss: 0.327164  [22400/60000]\n",
            "loss: 0.595834  [24000/60000]\n",
            "loss: 0.343094  [25600/60000]\n",
            "loss: 0.559913  [27200/60000]\n",
            "loss: 0.570472  [28800/60000]\n",
            "loss: 0.289541  [30400/60000]\n",
            "loss: 0.559485  [32000/60000]\n",
            "loss: 0.185471  [33600/60000]\n",
            "loss: 0.195368  [35200/60000]\n",
            "loss: 0.337027  [36800/60000]\n",
            "loss: 0.363054  [38400/60000]\n",
            "loss: 0.790821  [40000/60000]\n",
            "loss: 0.597279  [41600/60000]\n",
            "loss: 0.379919  [43200/60000]\n",
            "loss: 0.453443  [44800/60000]\n",
            "loss: 0.457637  [46400/60000]\n",
            "loss: 0.323897  [48000/60000]\n",
            "loss: 0.326864  [49600/60000]\n",
            "loss: 0.209795  [51200/60000]\n",
            "loss: 0.338014  [52800/60000]\n",
            "loss: 0.552705  [54400/60000]\n",
            "loss: 0.322357  [56000/60000]\n",
            "loss: 0.544842  [57600/60000]\n",
            "loss: 0.305766  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.463062 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.348287  [    0/60000]\n",
            "loss: 0.331782  [ 1600/60000]\n",
            "loss: 0.452086  [ 3200/60000]\n",
            "loss: 0.352378  [ 4800/60000]\n",
            "loss: 0.251433  [ 6400/60000]\n",
            "loss: 0.481042  [ 8000/60000]\n",
            "loss: 0.521361  [ 9600/60000]\n",
            "loss: 0.246204  [11200/60000]\n",
            "loss: 0.303196  [12800/60000]\n",
            "loss: 0.117583  [14400/60000]\n",
            "loss: 0.691075  [16000/60000]\n",
            "loss: 0.163202  [17600/60000]\n",
            "loss: 0.220708  [19200/60000]\n",
            "loss: 0.865754  [20800/60000]\n",
            "loss: 0.321344  [22400/60000]\n",
            "loss: 0.589960  [24000/60000]\n",
            "loss: 0.340161  [25600/60000]\n",
            "loss: 0.554213  [27200/60000]\n",
            "loss: 0.563252  [28800/60000]\n",
            "loss: 0.287625  [30400/60000]\n",
            "loss: 0.562771  [32000/60000]\n",
            "loss: 0.183976  [33600/60000]\n",
            "loss: 0.192371  [35200/60000]\n",
            "loss: 0.339833  [36800/60000]\n",
            "loss: 0.349195  [38400/60000]\n",
            "loss: 0.791001  [40000/60000]\n",
            "loss: 0.592374  [41600/60000]\n",
            "loss: 0.382305  [43200/60000]\n",
            "loss: 0.453573  [44800/60000]\n",
            "loss: 0.456229  [46400/60000]\n",
            "loss: 0.319514  [48000/60000]\n",
            "loss: 0.319752  [49600/60000]\n",
            "loss: 0.205561  [51200/60000]\n",
            "loss: 0.339399  [52800/60000]\n",
            "loss: 0.549147  [54400/60000]\n",
            "loss: 0.309217  [56000/60000]\n",
            "loss: 0.542010  [57600/60000]\n",
            "loss: 0.303568  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 0.458943 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.341756  [    0/60000]\n",
            "loss: 0.329217  [ 1600/60000]\n",
            "loss: 0.441456  [ 3200/60000]\n",
            "loss: 0.347190  [ 4800/60000]\n",
            "loss: 0.248396  [ 6400/60000]\n",
            "loss: 0.479318  [ 8000/60000]\n",
            "loss: 0.521595  [ 9600/60000]\n",
            "loss: 0.241330  [11200/60000]\n",
            "loss: 0.298841  [12800/60000]\n",
            "loss: 0.114148  [14400/60000]\n",
            "loss: 0.689255  [16000/60000]\n",
            "loss: 0.160400  [17600/60000]\n",
            "loss: 0.213808  [19200/60000]\n",
            "loss: 0.849768  [20800/60000]\n",
            "loss: 0.315993  [22400/60000]\n",
            "loss: 0.583450  [24000/60000]\n",
            "loss: 0.337106  [25600/60000]\n",
            "loss: 0.548333  [27200/60000]\n",
            "loss: 0.556484  [28800/60000]\n",
            "loss: 0.286325  [30400/60000]\n",
            "loss: 0.565828  [32000/60000]\n",
            "loss: 0.182810  [33600/60000]\n",
            "loss: 0.189497  [35200/60000]\n",
            "loss: 0.342907  [36800/60000]\n",
            "loss: 0.336590  [38400/60000]\n",
            "loss: 0.790397  [40000/60000]\n",
            "loss: 0.587278  [41600/60000]\n",
            "loss: 0.385632  [43200/60000]\n",
            "loss: 0.453353  [44800/60000]\n",
            "loss: 0.454588  [46400/60000]\n",
            "loss: 0.315374  [48000/60000]\n",
            "loss: 0.312643  [49600/60000]\n",
            "loss: 0.201450  [51200/60000]\n",
            "loss: 0.341309  [52800/60000]\n",
            "loss: 0.546994  [54400/60000]\n",
            "loss: 0.297132  [56000/60000]\n",
            "loss: 0.539666  [57600/60000]\n",
            "loss: 0.301967  [59200/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.455065 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66c72467",
      "metadata": {
        "id": "66c72467"
      },
      "source": [
        "### Сохранение и загрузка модели\n",
        "\n",
        "Параметры модели могут быть сохранены в файл с помощью функции torch.save."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8f08e65",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8f08e65",
        "outputId": "813993cf-cb03-472a-f826-af9785ffb574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "939f54f8",
      "metadata": {
        "id": "939f54f8"
      },
      "source": [
        "Загрузка модели включает в себя создание новой модели с той же структурой и загрузку сохранённых параметров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18a9ba31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18a9ba31",
        "outputId": "b46e21c4-2b79-4546-aa2c-ae11ab8961b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3784fc0",
      "metadata": {
        "id": "d3784fc0"
      },
      "source": [
        "Загруженная модель может использоваться для определения классов изображений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49af016",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "f49af016",
        "outputId": "21151904-1dab-4727-fdbe-3f19297fc0a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Pullover\", Actual: \"Pullover\"\n",
            "torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[1][0], test_data[1][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "    plt.imshow(x.squeeze(), cmap = 'gray')\n",
        "print(test_data[0][0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f320cbb",
      "metadata": {
        "id": "3f320cbb"
      },
      "source": [
        "### Задание\n",
        "\n",
        "Попытайтесь улучшить качество распознавания, изменив функцию потерь, оптимизации, время обучения или структуру модели.\n",
        "<br>Загрузите фотографию предмета одежды, приведите её к необходимому размеру и используйте обученную нейронную сеть для определения класса.\n",
        "\n",
        "Было: batch: 64, epoches: 5, accuracy: 64%\n",
        "\n",
        "Стало: batch: 16, epoches: 20, accuracy: 84%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Загрузка изображения\n",
        "image = Image.open('sss.jpeg')\n",
        "\n",
        "# Преобразование изображения в формат, который может быть передан модели\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "image = transform(image).unsqueeze(0)\n",
        "\n",
        "# Предсказание класса\n",
        "with torch.no_grad():\n",
        "    pred = model(image)\n",
        "    predicted_class = pred.argmax(1).item()\n",
        "\n",
        "# Вывод предсказанного класса и изображения\n",
        "plt.imshow(transforms.ToPILImage()(image.squeeze()), cmap='gray')\n",
        "plt.title(classes[predicted_class])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "53mYDWVAKxUl",
        "outputId": "c5ceec6c-d479-4a8d-904a-e584d05a547e"
      },
      "id": "53mYDWVAKxUl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}