{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oHXNT9DWc2a"
      },
      "outputs": [],
      "source": [
        "#### Библиотеки\n",
        "# Стандартные библиотеки\n",
        "import json # библиотека для кодирования/декодирования данных/объектов Python\n",
        "import random # библиотека функций для генерации случайных значений\n",
        "import sys # библиотека для работы с переменными и функциями, имеющими отношение к интерпретатору и его окружению\n",
        "import gzip # библиотека для сжатия и распаковки файлов gzip и gunzip.\n",
        "# Сторонние библиотеки\n",
        "import numpy as np # библиотека функций для работы с матрицами\n",
        "import pickle # библиотека для сохранения и загрузки сложных объектов Python."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!cd \"/gdrive/My Drive/A\"\n",
        "!ls'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FO-QsYteus5-",
        "outputId": "dc6af14e-3d7b-4eaa-d64e-0961f17556bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from google.colab import drive\\ndrive.mount(\\'/gdrive\\')\\n!cd \"/gdrive/My Drive/A\"\\n!ls'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" -- Определение стоимостных функции --\"\"\"\n",
        "\n",
        "class QuadraticCost(object): # Определение среднеквадратичной стоимостной функции\n",
        "\n",
        "    @staticmethod\n",
        "    def fn(a, y): # Cтоимостная функция\n",
        "        return 0.5*np.linalg.norm(a-y)**2\n",
        "\n",
        "    @staticmethod\n",
        "    def delta(z, a, y):  # Мера влияния нейронов выходного слоя на величину ошибки\n",
        "        return (a-y) * sigmoid_prime(z)\n",
        "\n",
        "class CrossEntropyCost(object):  # Определение стоимостной функции на основе перекрестной энтропии\n",
        "\n",
        "    @staticmethod\n",
        "    def fn(a, y): # Cтоимостная функция\n",
        "        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
        "\n",
        "    @staticmethod\n",
        "    def delta(z, a, y): # Мера влияния нейронов выходного слоя на величину ошибки\n",
        "        return (a-y)"
      ],
      "metadata": {
        "id": "Wk8n8m03aIbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z): # определение сигмоидальной функции активации\n",
        "    return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):# Производная сигмоидальной функции\n",
        " return sigmoid(z)*(1-sigmoid(z))\n",
        "\n",
        "def load_data():\n",
        "    f = gzip.open('mnist.pkl.gz', 'rb') # открываем сжатый файл gzip вдвоичном режиме\n",
        "    training_data, validation_data, test_data = pickle.load(f, encoding='latin1') # загружам таблицы из файла\n",
        "\n",
        "    #training_data,  test_data = pickle.load(f, encoding='latin1')  # загружам таблицы из файла\n",
        "    f.close() # закрываем файл\n",
        "    return (training_data, validation_data, test_data)\n",
        "    #return (training_data,  test_data)\n",
        "\n",
        "\n",
        "def load_data_wrapper():\n",
        "    tr_d, va_d, te_d = load_data() # инициализация наборов данных в формате MNIST\n",
        "    #tr_d,  te_d = load_data()  # инициализация наборов данных в формате MNIST\n",
        "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]] # преобразование массивов размера 1 на 784 к массивам размера 784 на 1\n",
        "    training_results = [vectorized_result(y) for y in tr_d[1]] # представление цифр от 0 до 9 в виде массивов размера 10 на 1\n",
        "    training_data = zip(training_inputs, training_results) # формируем набор обучающих данных из пар (x, y)\n",
        "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]] # преобразование массивов размера 1 на 784 к массивам размера 784 на 1\n",
        "    validation_data = zip(validation_inputs, va_d[1]) # формируем набор данных проверки из пар (x, y)\n",
        "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]] # преобразование массивов размера 1 на 784 к массивам размера 784 на 1\n",
        "    test_data = zip(test_inputs, te_d[1]) # формируем набор тестовых данных из пар (x, y)\n",
        "    return (training_data, validation_data, test_data)\n",
        "    #return (training_data,  test_data)\n",
        "def vectorized_result(j):\n",
        "    e = np.zeros((10, 1))\n",
        "    e[j] = 1.0\n",
        "    return e"
      ],
      "metadata": {
        "id": "A4uDSE0YaSSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" --Описание класса Network--\"\"\"\n",
        "class Network(object):\n",
        "    def __init__( \t# конструктор класса\n",
        "        self \t\t\t# указатель на объект класса\n",
        "        , sizes\t\t# список размеров слоев нейронной сети\n",
        "        , cost=CrossEntropyCost\t# стоимостная функция (по умолчанию будет использоваться функция перекрестной энтропии)\n",
        "        ):\n",
        "        self.num_layers = len(sizes) # задаем количество слоев нейронной сети\n",
        "        self.sizes = sizes # задаем список размеров слоев нейронной сети\n",
        "        self.default_weight_initializer() # метод инициализации начальных весов связей и смещений по умолчанию\n",
        "        self.cost=cost # задаем стоимостную функцию\n",
        "\n",
        "    def default_weight_initializer(self): # метод инициализации начальных весов связей и смещений\n",
        "        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]] # задаем случайные начальные смещения\n",
        "        self.weights = [np.random.randn(y, x)/np.sqrt(x)\n",
        "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])] # задаем случайные начальные веса связей\n",
        "\n",
        "\n",
        "    def large_weight_initializer(self):\n",
        "        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]] # задаем случайные начальные смещения\n",
        "        self.weights = [np.random.randn(y, x)\n",
        "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])] # задаем случайные начальные веса\n",
        "\n",
        "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
        "            lmbda = 0.0 # параметр сглаживания L2-регуляризации\n",
        "            , evaluation_data=None # оценочная выборка\n",
        "            , monitor_evaluation_cost=False # флаг вывода на экран информа-ции о значении стоимостной функции в процессе обучения, рассчитанном на оценочной выборке\n",
        "            , monitor_evaluation_accuracy=False # флаг вывода на экран ин-формации о достигнутом прогрессе в обучении, рассчитанном на оценочной выборке\n",
        "            , monitor_training_cost=False # флаг вывода на экран информации о значении стоимостной функции в процессе обучения, рассчитанном на обучающей выборке\n",
        "            , monitor_training_accuracy=False # флаг вывода на экран инфор-мации о достигнутом прогрессе в обучении, рассчитанном на обучающей выборке\n",
        "            ):\n",
        "        if evaluation_data:\n",
        "            evaluation_data = list(evaluation_data)\n",
        "            n_data = len(evaluation_data)\n",
        "        training_data = list(training_data)\n",
        "        n = len(training_data)\n",
        "        evaluation_cost, evaluation_accuracy = [], []\n",
        "        training_cost, training_accuracy = [], []\n",
        "        for j in range(epochs):\n",
        "            random.shuffle(training_data)\n",
        "            mini_batches = [\n",
        "                training_data[k:k+mini_batch_size]\n",
        "                for k in range(0, n, mini_batch_size)]\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(\n",
        "                    mini_batch, eta, lmbda, len(training_data))\n",
        "            print (\"\\nEpoch %s training complete\" % j)\n",
        "            if monitor_training_cost:\n",
        "                cost = self.total_cost(training_data, lmbda)\n",
        "                training_cost.append(cost)\n",
        "                print (\"--Cost on training data: {}\".format(cost))\n",
        "            if monitor_training_accuracy:\n",
        "                accuracy = self.accuracy(training_data, convert=True)\n",
        "                training_accuracy.append(accuracy)\n",
        "                print (\"--Accuracy on training data: {} / {}\".format(\n",
        "                    accuracy, n))\n",
        "            if monitor_evaluation_cost:\n",
        "                cost = self.total_cost(evaluation_data, lmbda, convert=True)\n",
        "                evaluation_cost.append(cost)\n",
        "                print (\"--Cost on evaluation data: {}\".format(cost))\n",
        "            if monitor_evaluation_accuracy:\n",
        "                accuracy = self.accuracy(evaluation_data)\n",
        "                evaluation_accuracy.append(accuracy)\n",
        "                print (\"--Accuracy on evaluation data: {} / {}\".format(\n",
        "                    self.accuracy(evaluation_data), n_data))\n",
        "            print\n",
        "        return evaluation_cost, evaluation_accuracy, \\\n",
        "            training_cost, training_accuracy\n",
        "\n",
        "\n",
        "    def update_mini_batch( # Шаг градиентного спуска\n",
        "         self              # указатель на объект класса\n",
        "         , mini_batch      # подвыборка\n",
        "         , eta             # скорость обучения\n",
        "         , lmbda           # параметр сглаживания L2-регуляризации\n",
        "         , n               #\n",
        "         ):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases] # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights] # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y) # послойно вычисляем градиенты dC/db и dC/dw для текущего прецедента (x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)] # суммируем градиенты dC/db для различных прецедентов текущей подвыборки\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)] # суммируем градиенты dC/dw для различных прецедентов текущей подвыборки\n",
        "        self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw\n",
        "                        for w, nw in zip(self.weights, nabla_w)] # обновляем все веса w нейронной сети\n",
        "        self.biases = [b-(eta/len(mini_batch))*nb\n",
        "                       for b, nb in zip(self.biases, nabla_b)] # обновляем все смещения b нейронной сети\n",
        "\n",
        "    def backprop(# Алгоритм обратного распространения\n",
        "        self   # Указатель на объект класса\n",
        "        , x    # Вектор входных сигналов\n",
        "        , y    # Ожидаемый вектор выходных сигналов\n",
        "        ):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases] # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights] # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "\n",
        "        # Определение переменных\n",
        "        activation = x # Выходные сигналы слоя (первоначально соответствует выходным сигналам 1-го слоя или входным сигналам сети)\n",
        "        activations = [x] # Список выходных сигналов по всем слоям (первоначально содержит только выходные сигналы 1-го слоя)\n",
        "        zs = [] # Список активационных потенциалов по всем слоям (первоначально пуст)\n",
        "\n",
        "        # Прямое распространение\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            z = np.dot(w, activation)+b # Считаем активационные потенциалы текущего слоя\n",
        "            zs.append(z) # Добавляем элемент (активационные потенциалы слоя) в конец списка\n",
        "            activation = sigmoid(z) # Считаем выходные сигналы текущего слоя, применяя сигмоидальную функцию активации к активационным потенциалам слоя\n",
        "            activations.append(activation) # Добавляем элемент (выходные сигналы слоя) в конец списка\n",
        "\n",
        "        # Обратное распространение\n",
        "        delta = (self.cost).delta(zs[-1], activations[-1], y) # Считаем меру влияния нейронов выходного слоя L на величину ошибки (BP1)\n",
        "        nabla_b[-1] = delta # Градиент dC/db для слоя L (BP3)\n",
        "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())# Градиент dC/dw для слоя L (BP4)\n",
        "\n",
        "        for l in range(2, self.num_layers):\n",
        "            z = zs[-l] # Активационные потенциалы l-го слоя (двигаемся по списку справа налево)\n",
        "            sp = sigmoid_prime(z) # Считаем сигмоидальную функцию от активационных потенциалов l-го слоя\n",
        "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp # Считаем меру влияния нейронов l-го слоя  на величину ошибки (BP2)\n",
        "            nabla_b[-l] = delta # Градиент dC/db для l-го слоя (BP3)\n",
        "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
        "        return (nabla_b, nabla_w) # Градиент dC/dw для l-го слоя (BP4)\n",
        "\n",
        "    def feedforward(self, a):\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = sigmoid(np.dot(w, a) + b)\n",
        "        return a\n",
        "\n",
        "    def accuracy(# Оценка прогресса в обучении\n",
        "         self # Указатель на объект класса\n",
        "         , data # Набор данных (выборка)\n",
        "         , convert=False # Признак необходимости изменять формат представления результата работы нейронной сети\n",
        "         ):\n",
        "        if convert:\n",
        "            results = [(np.argmax(self.feedforward(x)), np.argmax(y))\n",
        "                       for (x, y) in data]\n",
        "        else:\n",
        "            results = [(np.argmax(self.feedforward(x)), y)\n",
        "                        for (x, y) in data]\n",
        "        return sum(int(x == y) for (x, y) in results)\n",
        "\n",
        "    def total_cost(# Значение функции потерь по всей выборке\n",
        "         self # Указатель на объект класса\n",
        "         , data # Набор данных (выборка)\n",
        "         , lmbda # Параметр сглаживания L2-регуляризации\n",
        "         , convert=False # Признак необходимости изменять формат представления результата работы нейронной сети\n",
        "         ):\n",
        "        cost = 0.0\n",
        "        data = list(data)\n",
        "        for x, y in data:\n",
        "            a = self.feedforward(x)\n",
        "            if convert: y = vectorized_result(y)\n",
        "            cost += self.cost.fn(a, y)/len(data)\n",
        "        cost += 0.5*(lmbda/len(data))*sum(\n",
        "            np.linalg.norm(w)**2 for w in self.weights)\n",
        "        return cost\n",
        "\n",
        "    def save(self, filename): # Запись нейронной сети в файл\n",
        "            data = {\"sizes\": self.sizes,\n",
        "                    \"weights\": [w.tolist() for w in self.weights],\n",
        "                    \"biases\": [b.tolist() for b in self.biases],\n",
        "                    \"cost\": str(self.cost.__name__)}\n",
        "            f = open(filename, \"w\")\n",
        "            json.dump(data, f)\n",
        "            f.close()\n",
        "\n",
        "    def load(filename): # Загрузка нейронной сети из файла\n",
        "\n",
        "        f = open(filename, \"r\")\n",
        "        data = json.load(f)\n",
        "        f.close()\n",
        "        cost = getattr(sys.modules[__name__], data[\"cost\"])\n",
        "        net = Network(data[\"sizes\"], cost=cost)\n",
        "        net.weights = [np.array(w) for w in data[\"weights\"]]\n",
        "        net.biases = [np.array(b) for b in data[\"biases\"]]\n",
        "        return net"
      ],
      "metadata": {
        "id": "QCoLHjEIug7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, validation_data, test_data = load_data_wrapper()"
      ],
      "metadata": {
        "id": "dQo3HZRSaGPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network([784, 30, 10], cost=CrossEntropyCost)\n",
        "net.SGD(training_data, 10, 10, 0.5, lmbda = 5.0,evaluation_data=validation_data,\n",
        "        monitor_evaluation_accuracy=True, monitor_evaluation_cost=True, monitor_training_accuracy=True, monitor_training_cost=True)\n",
        "net.save(\"weights.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LbGcVK5Y8CZ",
        "outputId": "d7a9461e-4706-41a2-f56e-7a857294c254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 training complete\n",
            "--Cost on training data: 0.4760768678805002\n",
            "--Accuracy on training data: 47062 / 50000\n",
            "--Cost on evaluation data: 0.7782383790098987\n",
            "--Accuracy on evaluation data: 9424 / 10000\n",
            "\n",
            "Epoch 1 training complete\n",
            "--Cost on training data: 0.45946085513369306\n",
            "--Accuracy on training data: 47345 / 50000\n",
            "--Cost on evaluation data: 0.8637817283980281\n",
            "--Accuracy on evaluation data: 9471 / 10000\n",
            "\n",
            "Epoch 2 training complete\n",
            "--Cost on training data: 0.5050836175962895\n",
            "--Accuracy on training data: 47021 / 50000\n",
            "--Cost on evaluation data: 0.9626949526561603\n",
            "--Accuracy on evaluation data: 9398 / 10000\n",
            "\n",
            "Epoch 3 training complete\n",
            "--Cost on training data: 0.39665289613286614\n",
            "--Accuracy on training data: 48050 / 50000\n",
            "--Cost on evaluation data: 0.8824737650548857\n",
            "--Accuracy on evaluation data: 9576 / 10000\n",
            "\n",
            "Epoch 4 training complete\n",
            "--Cost on training data: 0.4153272552705549\n",
            "--Accuracy on training data: 47925 / 50000\n",
            "--Cost on evaluation data: 0.9310631702869661\n",
            "--Accuracy on evaluation data: 9526 / 10000\n",
            "\n",
            "Epoch 5 training complete\n",
            "--Cost on training data: 0.40196320244129097\n",
            "--Accuracy on training data: 48063 / 50000\n",
            "--Cost on evaluation data: 0.9348652354235083\n",
            "--Accuracy on evaluation data: 9537 / 10000\n",
            "\n",
            "Epoch 6 training complete\n",
            "--Cost on training data: 0.4228972773808326\n",
            "--Accuracy on training data: 47921 / 50000\n",
            "--Cost on evaluation data: 0.9540372151382068\n",
            "--Accuracy on evaluation data: 9537 / 10000\n",
            "\n",
            "Epoch 7 training complete\n",
            "--Cost on training data: 0.41150580288420846\n",
            "--Accuracy on training data: 48018 / 50000\n",
            "--Cost on evaluation data: 0.9671187509692044\n",
            "--Accuracy on evaluation data: 9529 / 10000\n",
            "\n",
            "Epoch 8 training complete\n",
            "--Cost on training data: 0.3896512988432873\n",
            "--Accuracy on training data: 48224 / 50000\n",
            "--Cost on evaluation data: 0.9449740184440154\n",
            "--Accuracy on evaluation data: 9576 / 10000\n",
            "\n",
            "Epoch 9 training complete\n",
            "--Cost on training data: 0.3793080632040795\n",
            "--Accuracy on training data: 48355 / 50000\n",
            "--Cost on evaluation data: 0.9389954100040259\n",
            "--Accuracy on evaluation data: 9597 / 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = Network([784, 30, 10], cost=CrossEntropyCost)\n",
        "net2 = Network.load(\"weights.json\")\n",
        "net.SGD(training_data, 1, 10, 0.5, lmbda = 5.0,evaluation_data=validation_data,\n",
        "        monitor_evaluation_accuracy=True, monitor_evaluation_cost=True, monitor_training_accuracy=True, monitor_training_cost=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68MHprPOMykx",
        "outputId": "c08692ec-f54f-4cff-cfb6-888624b98d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 training complete\n",
            "--Cost on training data: 0.38923920786187266\n",
            "--Accuracy on training data: 48213 / 50000\n",
            "--Cost on evaluation data: 0.9302826799117148\n",
            "--Accuracy on evaluation data: 9594 / 10000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.9302826799117148], [9594], [0.38923920786187266], [48213])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}